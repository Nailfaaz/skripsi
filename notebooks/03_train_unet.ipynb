{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "234df2ee",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root added to sys.path: c:\\Users\\nailf\\Desktop\\skripsi\n"
          ]
        }
      ],
      "source": [
        "# ─── PATH HACK FOR NOTEBOOK ───────────────────────────────────────────\n",
        "import os, sys\n",
        "\n",
        "# 1) assume the notebook lives in \"notebooks/\" and src/ is one level up:\n",
        "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "\n",
        "print(\"Project root added to sys.path:\", PROJECT_ROOT)\n",
        "# ─────────────────────────────────────────────────────────────────────"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0ce5ce76",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from src.models.unet import UNet\n",
        "\n",
        "model = UNet(n_channels=1, n_classes=1)\n",
        "x = torch.randn(2, 1, 224, 224)       # batch of 2, 224×224\n",
        "y = model(x)\n",
        "print(y.shape)  # should be (2, 1, 224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1d6ea2df",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9eddfa1021d40de8cfba30f78656a77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/99 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03b3dd6b72254e128cda0fbc34572790",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validate:   0%|          | 0/22 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Epoch results — Train Loss: 0.1756 | Val Loss: 0.1059 | Val Dice: 0.9249\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from torch.utils.data import DataLoader\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from src.data.loader import NpySegDataset\n",
        "from src.models.unet import UNet\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Absolute paths\n",
        "PROJECT_ROOT   = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "shenzhen_root  = os.path.join(PROJECT_ROOT, \"data/processed/shenzhen\")\n",
        "\n",
        "# Datasets & Loaders\n",
        "train_ds = NpySegDataset(shenzhen_root, split=\"train\")\n",
        "val_ds   = NpySegDataset(shenzhen_root, split=\"val\")\n",
        "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True,  num_workers=2)\n",
        "val_dl   = DataLoader(val_ds,   batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "# Model + optimizer + loss\n",
        "device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model     = UNet(n_channels=1, n_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn   = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def dice_coef(pred, target, eps=1e-6):\n",
        "    p = (pred > 0.5).float()\n",
        "    t = target.float()\n",
        "    intersect = (p * t).sum(dim=[1,2,3])\n",
        "    union = p.sum(dim=[1,2,3]) + t.sum(dim=[1,2,3])\n",
        "    return ((2*intersect + eps) / (union + eps)).mean().item()\n",
        "\n",
        "# Training + validation loop for 1 epoch\n",
        "model.train()\n",
        "train_loss = 0.0\n",
        "for imgs, masks in tqdm(train_dl, desc=\"Train\", unit=\"batch\"):\n",
        "    imgs, masks = imgs.to(device), masks.to(device).float()\n",
        "    preds       = model(imgs)\n",
        "    loss        = loss_fn(preds, masks)\n",
        "    optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "train_loss /= len(train_dl)\n",
        "\n",
        "model.eval()\n",
        "val_loss = 0.0\n",
        "val_dice = 0.0\n",
        "with torch.no_grad():\n",
        "    for imgs, masks in tqdm(val_dl, desc=\"Validate\", unit=\"batch\"):\n",
        "        imgs, masks = imgs.to(device), masks.to(device).float()\n",
        "        preds       = model(imgs)\n",
        "        val_loss   += loss_fn(preds, masks).item()\n",
        "        val_dice   += dice_coef(torch.sigmoid(preds), masks)\n",
        "val_loss /= len(val_dl)\n",
        "val_dice /= len(val_dl)\n",
        "\n",
        "print(f\"\\n✅ Epoch results — Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee631cb",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
